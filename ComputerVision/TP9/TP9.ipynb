{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\"> Compte rendu de TP 9 </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "Dans ce compte rendu, nous allons présenter un système simple de détection de sentiments à partir de documents. Pour ce faire, nous disposons d'une base de référence contenant un corpus de 200 phrases réparties en deux classes de sentiments : 100 phrases pour les sentiments négatifs et 100 pour les sentiments positifs. La base de test est composée de 100 phrases, 50 pour chaque classe. L'objectif est de soumettre ces phrases à notre système qui déterminera si elles appartiennent à la classe positive ou négative.\n",
    "\n",
    "## Méthodologie du Système\n",
    "\n",
    "Notre démarche pour la détection de sentiments comprend les étapes suivantes :\n",
    "\n",
    "1. **Prétraitement des Données** : Tout d'abord, nous commençons par la lecture des fichiers de la base de référence. Ensuite, nous appliquons un ensemble de techniques de prétraitement, notamment :\n",
    "   - Mise en minuscules : Conversion de tous les textes en minuscules pour une cohérence.\n",
    "   - Nettoyage de la ponctuation : Suppression de la ponctuation pour éviter tout bruit inutile.\n",
    "   - Élimination des mots vides : Retrait des mots courants (stop words) qui n'apportent pas d'informations significatives.\n",
    "   - Stemming : Réduction des mots à leur forme racine pour normaliser le texte.\n",
    "\n",
    "\n",
    "2. **Vectorisation des Phrases** : Pour chaque phrase de la base de référence, nous effectuons la vectorisation en calculant le TF-IDF (Term Frequency-Inverse Document Frequency) de chaque mot. Cela nous permet de représenter chaque phrase sous forme de vecteur.\n",
    "\n",
    "3. **Prétraitement et Vectorisation des Documents de Test** : Nous appliquons les mêmes étapes de prétraitement et de vectorisation aux documents de test, de manière à les préparer pour la phase de classification.\n",
    "\n",
    "4. **Calcul des Distances** : Nous calculons les distances entre les vecteurs des documents de test et les vecteurs de référence des classes positives et négatives. Nous utilisons deux méthodes de calcul de distance :\n",
    "   - Méthode de Cosinus : Nous mesurons la similarité cosinus entre les vecteurs, prenant en compte la proximité à 1. En fonction de cette similarité, nous prenons une décision quant à l'appartenance de la phrase à la classe positive ou négative.\n",
    "   - Méthode de Bray-Curtis : Dans cette méthode, nous calculons la distance de Bray-Curtis et évaluons la proximité à 0. En fonction de cette distance, nous déterminons si la phrase appartient à la classe positive ou négative.\n",
    "\n",
    "\n",
    "5. **Évaluation du Système et Comparaison des Méthodes** : Après avoir effectué la classification, nous passons à l'évaluation de la performance de notre système. Nous utilisons des mesures d'évaluation telles que l'exactitude, la précision, le rappel et la F-mesure pour quantifier son efficacité dans la classification des sentiments. De plus, nous comparons les résultats des deux méthodes de calcul de distance pour déterminer laquelle est la plus performante.\n",
    "\n",
    "Cette méthodologie nous permet de réaliser une classification de sentiments basique en se basant sur des techniques de traitement de texte et de vectorisation. Elle peut servir de point de départ pour des tâches de détection de sentiments plus avancées.\n",
    "\n",
    "En suivant ces étapes, notre système est capable de classer les phrases de test en fonction de leur sentiment, en utilisant les vecteurs et les distances calculées.\n",
    "\n",
    "Cette méthodologie nous permet de réaliser une classification de sentiments basique en se basant sur des techniques de traitement de texte et de vectorisation. Elle peut servir de point de départ pour des tâches de détection de sentiments plus avancées."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mise en Place des Outils Essentiels\n",
    "\n",
    "Dans cette section, nous allons implementer les outils et les bibliothèques nécessaires pour la mise en place de notre système de détection de sentiments. Avant de plonger dans les détails de l'implémentation, assurons-nous d'avoir tous les éléments nécessaires.\n",
    "\n",
    "## Implementation de la fonction du prétraitement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer as ps\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def lemmatization(tokens):\n",
    "    return [lemmatizer.lemmatize(word) for word in tokens]\n",
    "\n",
    "stemmer = ps()\n",
    "\n",
    "def clean_words(text) :\n",
    "    # remove html markup\n",
    "    text = re.sub(\"(<.*?.>)\", \"\", text)\n",
    "    # remove non-ascii and digits\n",
    "    text = re.sub(r'[^\\w\\s]', \"\", text)\n",
    "    return text\n",
    "  \n",
    "\n",
    "# nltk.download('wordnet')\n",
    "\n",
    "def tokenisation(cont) :\n",
    "  stop_words = set(stopwords.words('english'))\n",
    "  tokens = word_tokenize(cont)\n",
    "  tokens = [word for word in tokens if not word in stop_words]\n",
    "  return tokens\n",
    "  \n",
    "\n",
    "def stemming(tokens) :\n",
    "  \n",
    "  return [stemmer.stem(word = word) for word in tokens]  \n",
    "  \n",
    "def pretraitement(doc) :\n",
    "  doc = doc.lower()\n",
    "  doc = clean_words(doc)\n",
    "  tokens = tokenisation(doc)\n",
    "  # stems = lemmatization(tokens)\n",
    "  stems = stemming(tokens)\n",
    "  \n",
    "  return stems\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation de la fonction TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def TFIDF(treated_doc, doc_collection):\n",
    "    TFIDF = []\n",
    "    # on faire le traitement pour chaque mot dans notre document \n",
    "    for word in treated_doc :\n",
    "    # Calcul de la fréquence du terme (TF) dans le document\n",
    "      TF = treated_doc.count(word) / len(treated_doc)\n",
    "      \n",
    "      # Calcul de la fréquence inverse de document (IDF) :\n",
    "      N = len(doc_collection)  # Nombre total de documents dans la collection\n",
    "      DF = 0  # Initialise le décompte de documents contenant le terme\n",
    "      \n",
    "      # Parcours de la collection de documents pour compter le nombre de documents contenant le terme\n",
    "      for doc in doc_collection:\n",
    "          if word in doc:\n",
    "              DF += 1\n",
    "      \n",
    "      # Calcul de l'IDF en utilisant la formule standard : log(N / DF)\n",
    "      IDF = math.log(N / DF)  # Note : Vous pouvez envisager d'ajouter 1 au dénominateur pour éviter la division par zéro\n",
    "      \n",
    "      # Calcul du score final TF-IDF en multipliant TF par IDF\n",
    "      TFIDF.append(TF * IDF)\n",
    "    \n",
    "    # en retoure un vecteur des TF-IDF de chaque mot de la document\n",
    "    return TFIDF\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation de la fonction Cosinus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def simCosine(v1, v2):\n",
    "    \"\"\"\n",
    "    Calcule la similarité cosinus entre deux vecteurs.\n",
    "\n",
    "    Cette fonction calcule la similarité cosinus entre deux vecteurs d'entrée en les redimensionnant à la même longueur,\n",
    "    en calculant le produit scalaire (S1) et la magnitude de chaque vecteur (S2 et S3), puis renvoie la similarité cosinus.\n",
    "\n",
    "    Args:\n",
    "        v1: Le premier vecteur.\n",
    "        v2: Le deuxième vecteur.\n",
    "\n",
    "    Returns:\n",
    "        La similarité cosinus entre les deux vecteurs d'entrée.\n",
    "    \"\"\"\n",
    "\n",
    "    # Redimensionner les vecteurs pour qu'ils aient la même longueur\n",
    "    mini = v2 if len(v1) > len(v2) else v1\n",
    "    maxi = v1 if len(v1) > len(v2) else v2\n",
    "    N = len(maxi)\n",
    "\n",
    "    S1 = 0  # Initialisation du produit scalaire\n",
    "    S2 = 0  # Initialisation de la magnitude de v1\n",
    "    S3 = 0  # Initialisation de la magnitude de v2\n",
    "\n",
    "    # Compléter le vecteur le plus court avec des zéros\n",
    "    for i in range(N - len(mini)):\n",
    "        mini.append(0)\n",
    "\n",
    "    # Calcul du produit scalaire S1 et des magnitudes S2 et S3\n",
    "    for i in range(N):\n",
    "        S1 += maxi[i] * mini[i]\n",
    "        S2 += maxi[i] ** 2\n",
    "        S3 += mini[i] ** 2\n",
    "\n",
    "    # Calcul de la similarité cosinus\n",
    "    similarity = S1 / (math.sqrt(S2) * math.sqrt(S3))\n",
    "    \n",
    "    return similarity\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation de la fonciton Bray-Curtis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simBray(v1, v2):\n",
    "    \"\"\"\n",
    "    Calcule la distance de Bray-Curtis entre deux vecteurs.r \n",
    "\n",
    "    Cette fonction calcule la distance de Bray-Curtis entre deux vecteurs d'entrée en redimensionnant les vecteurs,\n",
    "    puis en effectuant des calculs sur les composants des vecteurs et renvoie la distance de Bray-Curtis.\n",
    "\n",
    "    Args:\n",
    "        v1: Le premier vecteur.\n",
    "        v2: Le deuxième vecteur.\n",
    "\n",
    "    Returns:\n",
    "        La distance de Bray-Curtis entre les deux vecteurs d'entrée.\n",
    "    \"\"\"\n",
    "\n",
    "    # Redimensionner les vecteurs pour qu'ils aient la même longueur\n",
    "    mini = v2 if len(v1) > len(v2) else v1\n",
    "    maxi = v1 if len(v1) > len(v2) else v2\n",
    "    N = len(maxi)\n",
    "\n",
    "    S1 = 0  # Initialisation du numérateur\n",
    "    S2 = 0  # Initialisation du dénominateur\n",
    "\n",
    "    # Compléter le vecteur le plus court avec des zéros\n",
    "    for i in range(N - len(mini)):\n",
    "        mini.append(0)\n",
    "\n",
    "    # Calcul du numérateur S1 et du dénominateur S2\n",
    "    for i in range(N):\n",
    "        S1 += min(maxi[i], mini[i])\n",
    "        S2 += maxi[i] + mini[i]\n",
    "\n",
    "    # Calcul de la distance de Bray-Curtis\n",
    "    bray_curtis_distance = (2 * S1) / S2\n",
    "    \n",
    "    return bray_curtis_distance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation du Système\n",
    "\n",
    "## Lecture des documents de référence\n",
    "\n",
    "### Pour le document de référence positive : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "SystemError",
     "evalue": "<built-in function isinstance> returned a result with an exception set",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: partially initialized module 'pandas' has no attribute '_pandas_datetime_CAPI' (most likely due to a circular import)",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mSystemError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      2\u001b[0m pd\u001b[38;5;241m.\u001b[39mset_option(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdisplay.max_rows\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m10\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# On intialise le tableau pour stocker les documents ligne par ligne\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/__init__.py:46\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m# let init-time option registration happen\u001b[39;00m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig_init\u001b[39;00m  \u001b[38;5;66;03m# pyright: ignore[reportUnusedImport] # noqa: F401\u001b[39;00m\n\u001b[0;32m---> 46\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;66;03m# dtype\u001b[39;00m\n\u001b[1;32m     48\u001b[0m     ArrowDtype,\n\u001b[1;32m     49\u001b[0m     Int8Dtype,\n\u001b[1;32m     50\u001b[0m     Int16Dtype,\n\u001b[1;32m     51\u001b[0m     Int32Dtype,\n\u001b[1;32m     52\u001b[0m     Int64Dtype,\n\u001b[1;32m     53\u001b[0m     UInt8Dtype,\n\u001b[1;32m     54\u001b[0m     UInt16Dtype,\n\u001b[1;32m     55\u001b[0m     UInt32Dtype,\n\u001b[1;32m     56\u001b[0m     UInt64Dtype,\n\u001b[1;32m     57\u001b[0m     Float32Dtype,\n\u001b[1;32m     58\u001b[0m     Float64Dtype,\n\u001b[1;32m     59\u001b[0m     CategoricalDtype,\n\u001b[1;32m     60\u001b[0m     PeriodDtype,\n\u001b[1;32m     61\u001b[0m     IntervalDtype,\n\u001b[1;32m     62\u001b[0m     DatetimeTZDtype,\n\u001b[1;32m     63\u001b[0m     StringDtype,\n\u001b[1;32m     64\u001b[0m     BooleanDtype,\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;66;03m# missing\u001b[39;00m\n\u001b[1;32m     66\u001b[0m     NA,\n\u001b[1;32m     67\u001b[0m     isna,\n\u001b[1;32m     68\u001b[0m     isnull,\n\u001b[1;32m     69\u001b[0m     notna,\n\u001b[1;32m     70\u001b[0m     notnull,\n\u001b[1;32m     71\u001b[0m     \u001b[38;5;66;03m# indexes\u001b[39;00m\n\u001b[1;32m     72\u001b[0m     Index,\n\u001b[1;32m     73\u001b[0m     CategoricalIndex,\n\u001b[1;32m     74\u001b[0m     RangeIndex,\n\u001b[1;32m     75\u001b[0m     MultiIndex,\n\u001b[1;32m     76\u001b[0m     IntervalIndex,\n\u001b[1;32m     77\u001b[0m     TimedeltaIndex,\n\u001b[1;32m     78\u001b[0m     DatetimeIndex,\n\u001b[1;32m     79\u001b[0m     PeriodIndex,\n\u001b[1;32m     80\u001b[0m     IndexSlice,\n\u001b[1;32m     81\u001b[0m     \u001b[38;5;66;03m# tseries\u001b[39;00m\n\u001b[1;32m     82\u001b[0m     NaT,\n\u001b[1;32m     83\u001b[0m     Period,\n\u001b[1;32m     84\u001b[0m     period_range,\n\u001b[1;32m     85\u001b[0m     Timedelta,\n\u001b[1;32m     86\u001b[0m     timedelta_range,\n\u001b[1;32m     87\u001b[0m     Timestamp,\n\u001b[1;32m     88\u001b[0m     date_range,\n\u001b[1;32m     89\u001b[0m     bdate_range,\n\u001b[1;32m     90\u001b[0m     Interval,\n\u001b[1;32m     91\u001b[0m     interval_range,\n\u001b[1;32m     92\u001b[0m     DateOffset,\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;66;03m# conversion\u001b[39;00m\n\u001b[1;32m     94\u001b[0m     to_numeric,\n\u001b[1;32m     95\u001b[0m     to_datetime,\n\u001b[1;32m     96\u001b[0m     to_timedelta,\n\u001b[1;32m     97\u001b[0m     \u001b[38;5;66;03m# misc\u001b[39;00m\n\u001b[1;32m     98\u001b[0m     Flags,\n\u001b[1;32m     99\u001b[0m     Grouper,\n\u001b[1;32m    100\u001b[0m     factorize,\n\u001b[1;32m    101\u001b[0m     unique,\n\u001b[1;32m    102\u001b[0m     value_counts,\n\u001b[1;32m    103\u001b[0m     NamedAgg,\n\u001b[1;32m    104\u001b[0m     array,\n\u001b[1;32m    105\u001b[0m     Categorical,\n\u001b[1;32m    106\u001b[0m     set_eng_float_format,\n\u001b[1;32m    107\u001b[0m     Series,\n\u001b[1;32m    108\u001b[0m     DataFrame,\n\u001b[1;32m    109\u001b[0m )\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdtypes\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdtypes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SparseDtype\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtseries\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m infer_freq\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/api.py:47\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconstruction\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m array\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mflags\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Flags\n\u001b[0;32m---> 47\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgroupby\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     48\u001b[0m     Grouper,\n\u001b[1;32m     49\u001b[0m     NamedAgg,\n\u001b[1;32m     50\u001b[0m )\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mindexes\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     52\u001b[0m     CategoricalIndex,\n\u001b[1;32m     53\u001b[0m     DatetimeIndex,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     59\u001b[0m     TimedeltaIndex,\n\u001b[1;32m     60\u001b[0m )\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mindexes\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatetimes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     62\u001b[0m     bdate_range,\n\u001b[1;32m     63\u001b[0m     date_range,\n\u001b[1;32m     64\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/groupby/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgroupby\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgeneric\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      2\u001b[0m     DataFrameGroupBy,\n\u001b[1;32m      3\u001b[0m     NamedAgg,\n\u001b[1;32m      4\u001b[0m     SeriesGroupBy,\n\u001b[1;32m      5\u001b[0m )\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgroupby\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgroupby\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GroupBy\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgroupby\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgrouper\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Grouper\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/groupby/generic.py:67\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapply\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     60\u001b[0m     GroupByApply,\n\u001b[1;32m     61\u001b[0m     maybe_mangle_lambdas,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     64\u001b[0m     warn_alias_replacement,\n\u001b[1;32m     65\u001b[0m )\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mcom\u001b[39;00m\n\u001b[0;32m---> 67\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframe\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataFrame\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgroupby\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     69\u001b[0m     base,\n\u001b[1;32m     70\u001b[0m     ops,\n\u001b[1;32m     71\u001b[0m )\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgroupby\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgroupby\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     73\u001b[0m     GroupBy,\n\u001b[1;32m     74\u001b[0m     GroupByPlot,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     78\u001b[0m     _transform_template,\n\u001b[1;32m     79\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/frame.py:142\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marrays\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msparse\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SparseFrameAccessor\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconstruction\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m    137\u001b[0m     ensure_wrapped_if_datetimelike,\n\u001b[1;32m    138\u001b[0m     extract_array,\n\u001b[1;32m    139\u001b[0m     sanitize_array,\n\u001b[1;32m    140\u001b[0m     sanitize_masked_array,\n\u001b[1;32m    141\u001b[0m )\n\u001b[0;32m--> 142\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgeneric\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m    143\u001b[0m     NDFrame,\n\u001b[1;32m    144\u001b[0m     make_doc,\n\u001b[1;32m    145\u001b[0m )\n\u001b[1;32m    146\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mindexers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m check_key_length\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mindexes\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m    148\u001b[0m     DatetimeIndex,\n\u001b[1;32m    149\u001b[0m     Index,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    153\u001b[0m     ensure_index_from_sequences,\n\u001b[1;32m    154\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/generic.py:146\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdtypes\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minference\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m    138\u001b[0m     is_hashable,\n\u001b[1;32m    139\u001b[0m     is_nested_list_like,\n\u001b[1;32m    140\u001b[0m )\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdtypes\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmissing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m    142\u001b[0m     isna,\n\u001b[1;32m    143\u001b[0m     notna,\n\u001b[1;32m    144\u001b[0m )\n\u001b[0;32m--> 146\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m    147\u001b[0m     algorithms \u001b[38;5;28;01mas\u001b[39;00m algos,\n\u001b[1;32m    148\u001b[0m     arraylike,\n\u001b[1;32m    149\u001b[0m     common,\n\u001b[1;32m    150\u001b[0m     indexing,\n\u001b[1;32m    151\u001b[0m     missing,\n\u001b[1;32m    152\u001b[0m     nanops,\n\u001b[1;32m    153\u001b[0m     sample,\n\u001b[1;32m    154\u001b[0m )\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marray_algos\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mreplace\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m should_use_regex\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marrays\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ExtensionArray\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/indexing.py:70\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconstruction\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     61\u001b[0m     array \u001b[38;5;28;01mas\u001b[39;00m pd_array,\n\u001b[1;32m     62\u001b[0m     extract_array,\n\u001b[1;32m     63\u001b[0m )\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mindexers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     65\u001b[0m     check_array_indexer,\n\u001b[1;32m     66\u001b[0m     is_list_like_indexer,\n\u001b[1;32m     67\u001b[0m     is_scalar_indexer,\n\u001b[1;32m     68\u001b[0m     length_of_indexer,\n\u001b[1;32m     69\u001b[0m )\n\u001b[0;32m---> 70\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mindexes\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     71\u001b[0m     Index,\n\u001b[1;32m     72\u001b[0m     MultiIndex,\n\u001b[1;32m     73\u001b[0m )\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m TYPE_CHECKING:\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcollections\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mabc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     77\u001b[0m         Hashable,\n\u001b[1;32m     78\u001b[0m         Sequence,\n\u001b[1;32m     79\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/indexes/api.py:20\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdtypes\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcast\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m find_common_type\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01malgorithms\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m safe_sort\n\u001b[0;32m---> 20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mindexes\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     21\u001b[0m     Index,\n\u001b[1;32m     22\u001b[0m     _new_Index,\n\u001b[1;32m     23\u001b[0m     ensure_index,\n\u001b[1;32m     24\u001b[0m     ensure_index_from_sequences,\n\u001b[1;32m     25\u001b[0m     get_unanimous_names,\n\u001b[1;32m     26\u001b[0m )\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mindexes\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcategory\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CategoricalIndex\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mindexes\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatetimes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DatetimeIndex\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/indexes/base.py:28\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_config\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     24\u001b[0m     get_option,\n\u001b[1;32m     25\u001b[0m     using_copy_on_write,\n\u001b[1;32m     26\u001b[0m )\n\u001b[0;32m---> 28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     29\u001b[0m     NaT,\n\u001b[1;32m     30\u001b[0m     algos \u001b[38;5;28;01mas\u001b[39;00m libalgos,\n\u001b[1;32m     31\u001b[0m     index \u001b[38;5;28;01mas\u001b[39;00m libindex,\n\u001b[1;32m     32\u001b[0m     lib,\n\u001b[1;32m     33\u001b[0m )\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minternals\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BlockValuesRefs\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mjoin\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mlibjoin\u001b[39;00m\n",
      "File \u001b[0;32mindex.pyx:33\u001b[0m, in \u001b[0;36minit pandas._libs.index\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1064\u001b[0m, in \u001b[0;36m_handle_fromlist\u001b[0;34m(module, fromlist, import_, recursive)\u001b[0m\n",
      "\u001b[0;31mSystemError\u001b[0m: <built-in function isinstance> returned a result with an exception set"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 10)\n",
    "# On intialise le tableau pour stocker les documents ligne par ligne\n",
    "pos_doc = []\n",
    "for line in open(\"BR_Sentiment_Positif.txt\", \"r\") :\n",
    "  pos_doc.append(line)\n",
    "  \n",
    "pds = pd.DataFrame({\"Phrase\" : pos_doc})\n",
    "pds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pour le document de référence negative : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Phrase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>would have a hard time sitting through this one\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>have a hard time sitting through this one\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Aggressive self-glorification and a manipulati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>self-glorification and a manipulative whitewash\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Trouble Every Day is a plodding mess .\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>ugly to look at and not a Hollywood product\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>bogged down in earnest dramaturgy\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>cheap\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Violent , vulgar and forgettably\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>vulgar\\n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Phrase\n",
       "0   would have a hard time sitting through this one\\n\n",
       "1         have a hard time sitting through this one\\n\n",
       "2   Aggressive self-glorification and a manipulati...\n",
       "3   self-glorification and a manipulative whitewash\\n\n",
       "4            Trouble Every Day is a plodding mess .\\n\n",
       "..                                                ...\n",
       "95      ugly to look at and not a Hollywood product\\n\n",
       "96                bogged down in earnest dramaturgy\\n\n",
       "97                                            cheap\\n\n",
       "98                 Violent , vulgar and forgettably\\n\n",
       "99                                           vulgar\\n\n",
       "\n",
       "[100 rows x 1 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg_doc = []\n",
    "for line in open(\"BR_Sentiment_Negatif.txt\", \"r\") :\n",
    "  neg_doc.append(line)\n",
    "  \n",
    "pds = pd.DataFrame({\"Phrase\" : neg_doc})\n",
    "pds  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prétraitement des documents de référence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pour le document de référence positive : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Phrase apres traitement</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This quiet , introspective and entertaining in...</td>\n",
       "      <td>[quiet, introspect, entertain, independ, worth...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>quiet , introspective and entertaining indepen...</td>\n",
       "      <td>[quiet, introspect, entertain, independ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>entertaining\\n</td>\n",
       "      <td>[entertain]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>is worth seeking\\n</td>\n",
       "      <td>[worth, seek]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A positively thrilling combination of ethnogra...</td>\n",
       "      <td>[posit, thrill, combin, ethnographi, intrigu, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>An unsettling , memorable cinematic experience...</td>\n",
       "      <td>[unsettl, memor, cinemat, experi]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>, memorable cinematic experience\\n</td>\n",
       "      <td>[memor, cinemat, experi]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>does its predecessors proud\\n</td>\n",
       "      <td>[predecessor, proud]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>proud\\n</td>\n",
       "      <td>[proud]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>it 's a pretty good execution of a story that ...</td>\n",
       "      <td>[pretti, good, execut, stori, lot, richer, one...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Phrase  \\\n",
       "0   This quiet , introspective and entertaining in...   \n",
       "1   quiet , introspective and entertaining indepen...   \n",
       "2                                      entertaining\\n   \n",
       "3                                  is worth seeking\\n   \n",
       "4   A positively thrilling combination of ethnogra...   \n",
       "..                                                ...   \n",
       "95  An unsettling , memorable cinematic experience...   \n",
       "96                 , memorable cinematic experience\\n   \n",
       "97                      does its predecessors proud\\n   \n",
       "98                                            proud\\n   \n",
       "99  it 's a pretty good execution of a story that ...   \n",
       "\n",
       "                              Phrase apres traitement  \n",
       "0   [quiet, introspect, entertain, independ, worth...  \n",
       "1            [quiet, introspect, entertain, independ]  \n",
       "2                                         [entertain]  \n",
       "3                                       [worth, seek]  \n",
       "4   [posit, thrill, combin, ethnographi, intrigu, ...  \n",
       "..                                                ...  \n",
       "95                  [unsettl, memor, cinemat, experi]  \n",
       "96                           [memor, cinemat, experi]  \n",
       "97                               [predecessor, proud]  \n",
       "98                                            [proud]  \n",
       "99  [pretti, good, execut, stori, lot, richer, one...  \n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "treated_pos_doc = [pretraitement(line) for line in pos_doc]\n",
    "pds = pd.DataFrame({\"Phrase\": pos_doc, \"Phrase apres traitement\" : treated_pos_doc})\n",
    "pds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pour le document de référence negative : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Phrase apres traitement</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>would have a hard time sitting through this one\\n</td>\n",
       "      <td>[would, hard, time, sit, one]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>have a hard time sitting through this one\\n</td>\n",
       "      <td>[hard, time, sit, one]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Aggressive self-glorification and a manipulati...</td>\n",
       "      <td>[aggress, selfglorif, manipul, whitewash]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>self-glorification and a manipulative whitewash\\n</td>\n",
       "      <td>[selfglorif, manipul, whitewash]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Trouble Every Day is a plodding mess .\\n</td>\n",
       "      <td>[troubl, everi, day, plod, mess]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>ugly to look at and not a Hollywood product\\n</td>\n",
       "      <td>[ugli, look, hollywood, product]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>bogged down in earnest dramaturgy\\n</td>\n",
       "      <td>[bog, earnest, dramaturgi]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>cheap\\n</td>\n",
       "      <td>[cheap]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Violent , vulgar and forgettably\\n</td>\n",
       "      <td>[violent, vulgar, forgett]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>vulgar\\n</td>\n",
       "      <td>[vulgar]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Phrase  \\\n",
       "0   would have a hard time sitting through this one\\n   \n",
       "1         have a hard time sitting through this one\\n   \n",
       "2   Aggressive self-glorification and a manipulati...   \n",
       "3   self-glorification and a manipulative whitewash\\n   \n",
       "4            Trouble Every Day is a plodding mess .\\n   \n",
       "..                                                ...   \n",
       "95      ugly to look at and not a Hollywood product\\n   \n",
       "96                bogged down in earnest dramaturgy\\n   \n",
       "97                                            cheap\\n   \n",
       "98                 Violent , vulgar and forgettably\\n   \n",
       "99                                           vulgar\\n   \n",
       "\n",
       "                      Phrase apres traitement  \n",
       "0               [would, hard, time, sit, one]  \n",
       "1                      [hard, time, sit, one]  \n",
       "2   [aggress, selfglorif, manipul, whitewash]  \n",
       "3            [selfglorif, manipul, whitewash]  \n",
       "4            [troubl, everi, day, plod, mess]  \n",
       "..                                        ...  \n",
       "95           [ugli, look, hollywood, product]  \n",
       "96                 [bog, earnest, dramaturgi]  \n",
       "97                                    [cheap]  \n",
       "98                 [violent, vulgar, forgett]  \n",
       "99                                   [vulgar]  \n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "treated_neg_doc = [pretraitement(line) for line in neg_doc]\n",
    "pds = pd.DataFrame({\"Phrase\": neg_doc, \"Phrase apres traitement\" : treated_neg_doc})\n",
    "pds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calcule de TF-IDF des document de référence\n",
    "\n",
    "### Pour le document de référence positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Phrase apres traitement</th>\n",
       "      <th>TF-IDF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This quiet , introspective and entertaining in...</td>\n",
       "      <td>[quiet, introspect, entertain, independ, worth...</td>\n",
       "      <td>[0.7675283643313486, 0.7675283643313486, 0.652...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>quiet , introspective and entertaining indepen...</td>\n",
       "      <td>[quiet, introspect, entertain, independ]</td>\n",
       "      <td>[1.151292546497023, 1.151292546497023, 0.97800...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>entertaining\\n</td>\n",
       "      <td>[entertain]</td>\n",
       "      <td>[3.912023005428146]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>is worth seeking\\n</td>\n",
       "      <td>[worth, seek]</td>\n",
       "      <td>[1.753278948659991, 2.302585092994046]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A positively thrilling combination of ethnogra...</td>\n",
       "      <td>[posit, thrill, combin, ethnographi, intrigu, ...</td>\n",
       "      <td>[0.35424386046062245, 0.3230542367599944, 0.35...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>An unsettling , memorable cinematic experience...</td>\n",
       "      <td>[unsettl, memor, cinemat, experi]</td>\n",
       "      <td>[1.151292546497023, 0.8381018043731808, 1.0499...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>, memorable cinematic experience\\n</td>\n",
       "      <td>[memor, cinemat, experi]</td>\n",
       "      <td>[1.1174690724975744, 1.3999016926266423, 1.399...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>does its predecessors proud\\n</td>\n",
       "      <td>[predecessor, proud]</td>\n",
       "      <td>[2.302585092994046, 2.0998525389399636]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>proud\\n</td>\n",
       "      <td>[proud]</td>\n",
       "      <td>[4.199705077879927]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>it 's a pretty good execution of a story that ...</td>\n",
       "      <td>[pretti, good, execut, stori, lot, richer, one...</td>\n",
       "      <td>[0.44152644721233636, 0.3499754231566606, 0.44...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Phrase  \\\n",
       "0   This quiet , introspective and entertaining in...   \n",
       "1   quiet , introspective and entertaining indepen...   \n",
       "2                                      entertaining\\n   \n",
       "3                                  is worth seeking\\n   \n",
       "4   A positively thrilling combination of ethnogra...   \n",
       "..                                                ...   \n",
       "95  An unsettling , memorable cinematic experience...   \n",
       "96                 , memorable cinematic experience\\n   \n",
       "97                      does its predecessors proud\\n   \n",
       "98                                            proud\\n   \n",
       "99  it 's a pretty good execution of a story that ...   \n",
       "\n",
       "                              Phrase apres traitement  \\\n",
       "0   [quiet, introspect, entertain, independ, worth...   \n",
       "1            [quiet, introspect, entertain, independ]   \n",
       "2                                         [entertain]   \n",
       "3                                       [worth, seek]   \n",
       "4   [posit, thrill, combin, ethnographi, intrigu, ...   \n",
       "..                                                ...   \n",
       "95                  [unsettl, memor, cinemat, experi]   \n",
       "96                           [memor, cinemat, experi]   \n",
       "97                               [predecessor, proud]   \n",
       "98                                            [proud]   \n",
       "99  [pretti, good, execut, stori, lot, richer, one...   \n",
       "\n",
       "                                               TF-IDF  \n",
       "0   [0.7675283643313486, 0.7675283643313486, 0.652...  \n",
       "1   [1.151292546497023, 1.151292546497023, 0.97800...  \n",
       "2                                 [3.912023005428146]  \n",
       "3              [1.753278948659991, 2.302585092994046]  \n",
       "4   [0.35424386046062245, 0.3230542367599944, 0.35...  \n",
       "..                                                ...  \n",
       "95  [1.151292546497023, 0.8381018043731808, 1.0499...  \n",
       "96  [1.1174690724975744, 1.3999016926266423, 1.399...  \n",
       "97            [2.302585092994046, 2.0998525389399636]  \n",
       "98                                [4.199705077879927]  \n",
       "99  [0.44152644721233636, 0.3499754231566606, 0.44...  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TFIDF_pos = []\n",
    "i = 0\n",
    "for line in treated_pos_doc:\n",
    "  TFIDF_pos.append(TFIDF(line, treated_pos_doc + treated_neg_doc))\n",
    "\n",
    "pds = pd.DataFrame({\"Phrase\": pos_doc, \"Phrase apres traitement\" : treated_pos_doc, \"TF-IDF\" : TFIDF_pos})\n",
    "pds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pour le document de référence negative : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Phrase apres traitement</th>\n",
       "      <th>TF-IDF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>would have a hard time sitting through this one\\n</td>\n",
       "      <td>[would, hard, time, sit, one]</td>\n",
       "      <td>[0.9210340371976184, 0.8399410155759854, 0.921...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>have a hard time sitting through this one\\n</td>\n",
       "      <td>[hard, time, sit, one]</td>\n",
       "      <td>[1.0499262694699818, 1.151292546497023, 1.1512...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Aggressive self-glorification and a manipulati...</td>\n",
       "      <td>[aggress, selfglorif, manipul, whitewash]</td>\n",
       "      <td>[1.324579341637009, 1.151292546497023, 1.15129...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>self-glorification and a manipulative whitewash\\n</td>\n",
       "      <td>[selfglorif, manipul, whitewash]</td>\n",
       "      <td>[1.5350567286626973, 1.5350567286626973, 1.535...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Trouble Every Day is a plodding mess .\\n</td>\n",
       "      <td>[troubl, everi, day, plod, mess]</td>\n",
       "      <td>[1.0596634733096073, 1.0596634733096073, 1.059...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>ugly to look at and not a Hollywood product\\n</td>\n",
       "      <td>[ugli, look, hollywood, product]</td>\n",
       "      <td>[0.683342002271625, 0.683342002271625, 0.66481...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>bogged down in earnest dramaturgy\\n</td>\n",
       "      <td>[bog, earnest, dramaturgi]</td>\n",
       "      <td>[1.7661057888493454, 1.7661057888493454, 1.766...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>cheap\\n</td>\n",
       "      <td>[cheap]</td>\n",
       "      <td>[5.298317366548036]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Violent , vulgar and forgettably\\n</td>\n",
       "      <td>[violent, vulgar, forgett]</td>\n",
       "      <td>[1.7661057888493454, 1.5350567286626973, 1.766...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>vulgar\\n</td>\n",
       "      <td>[vulgar]</td>\n",
       "      <td>[4.605170185988092]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Phrase  \\\n",
       "0   would have a hard time sitting through this one\\n   \n",
       "1         have a hard time sitting through this one\\n   \n",
       "2   Aggressive self-glorification and a manipulati...   \n",
       "3   self-glorification and a manipulative whitewash\\n   \n",
       "4            Trouble Every Day is a plodding mess .\\n   \n",
       "..                                                ...   \n",
       "95      ugly to look at and not a Hollywood product\\n   \n",
       "96                bogged down in earnest dramaturgy\\n   \n",
       "97                                            cheap\\n   \n",
       "98                 Violent , vulgar and forgettably\\n   \n",
       "99                                           vulgar\\n   \n",
       "\n",
       "                      Phrase apres traitement  \\\n",
       "0               [would, hard, time, sit, one]   \n",
       "1                      [hard, time, sit, one]   \n",
       "2   [aggress, selfglorif, manipul, whitewash]   \n",
       "3            [selfglorif, manipul, whitewash]   \n",
       "4            [troubl, everi, day, plod, mess]   \n",
       "..                                        ...   \n",
       "95           [ugli, look, hollywood, product]   \n",
       "96                 [bog, earnest, dramaturgi]   \n",
       "97                                    [cheap]   \n",
       "98                 [violent, vulgar, forgett]   \n",
       "99                                   [vulgar]   \n",
       "\n",
       "                                               TF-IDF  \n",
       "0   [0.9210340371976184, 0.8399410155759854, 0.921...  \n",
       "1   [1.0499262694699818, 1.151292546497023, 1.1512...  \n",
       "2   [1.324579341637009, 1.151292546497023, 1.15129...  \n",
       "3   [1.5350567286626973, 1.5350567286626973, 1.535...  \n",
       "4   [1.0596634733096073, 1.0596634733096073, 1.059...  \n",
       "..                                                ...  \n",
       "95  [0.683342002271625, 0.683342002271625, 0.66481...  \n",
       "96  [1.7661057888493454, 1.7661057888493454, 1.766...  \n",
       "97                                [5.298317366548036]  \n",
       "98  [1.7661057888493454, 1.5350567286626973, 1.766...  \n",
       "99                                [4.605170185988092]  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TFIDF_neg = []\n",
    "\n",
    "for line in treated_neg_doc:\n",
    "  TFIDF_neg.append(TFIDF(line, treated_pos_doc + treated_neg_doc))\n",
    "\n",
    "\n",
    "\n",
    "pds = pd.DataFrame({\"Phrase\": neg_doc, \"Phrase apres traitement\" : treated_neg_doc, \"TF-IDF\" : TFIDF_neg})\n",
    "pds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lecture des documemts de test\n",
    "\n",
    "### Document de test positive : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Phrases</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A smart , provocative drama that does the near...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A smart , provocative drama that does the near...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A smart , provocative drama that does the near...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A smart , provocative drama that does the near...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>smart , provocative drama\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>a particularly good film\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>particularly good film\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>particularly good\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>surprisingly ` solid ' achievement\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>One of recent memory 's most thoughtful films ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Phrases\n",
       "0   A smart , provocative drama that does the near...\n",
       "1   A smart , provocative drama that does the near...\n",
       "2   A smart , provocative drama that does the near...\n",
       "3   A smart , provocative drama that does the near...\n",
       "4                         smart , provocative drama\\n\n",
       "..                                                ...\n",
       "45                         a particularly good film\\n\n",
       "46                           particularly good film\\n\n",
       "47                                particularly good\\n\n",
       "48               surprisingly ` solid ' achievement\\n\n",
       "49  One of recent memory 's most thoughtful films ...\n",
       "\n",
       "[50 rows x 1 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_test = []\n",
    "for line in open(\"Test_Sentiment_Positif.txt\", \"r\") :\n",
    "  pos_test.append(line)\n",
    "  \n",
    "pds = pd.DataFrame({\"Phrases\" : pos_test})\n",
    "pd.set_option('display.max_rows', 20)\n",
    "pds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Document de test negative : \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Phrases</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>is trying to dupe the viewer into taking it al...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>trying to dupe the viewer into taking it all a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>to dupe the viewer into taking it all as Very ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dupe the viewer into taking it all as Very Imp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>simply because the movie is ugly to look at an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>an utterly incompetent conclusion\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>utterly incompetent conclusion\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>utterly incompetent\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Horrendously amateurish filmmaking that is pla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>filmmaking that is plainly dull and visually u...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Phrases\n",
       "0   is trying to dupe the viewer into taking it al...\n",
       "1   trying to dupe the viewer into taking it all a...\n",
       "2   to dupe the viewer into taking it all as Very ...\n",
       "3   dupe the viewer into taking it all as Very Imp...\n",
       "4   simply because the movie is ugly to look at an...\n",
       "..                                                ...\n",
       "45                an utterly incompetent conclusion\\n\n",
       "46                   utterly incompetent conclusion\\n\n",
       "47                              utterly incompetent\\n\n",
       "48  Horrendously amateurish filmmaking that is pla...\n",
       "49  filmmaking that is plainly dull and visually u...\n",
       "\n",
       "[50 rows x 1 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg_test = []\n",
    "for line in open(\"Test_Sentiment_Negatif.txt\", \"r\") :\n",
    "  neg_test.append(line)\n",
    "\n",
    "pds = pd.DataFrame({\"Phrases\" : neg_test})\n",
    "# pd.set_option('display.max_rows', 20)\n",
    "pds  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prétraitement des documents de test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pour le document de test positive : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Phrase apres traitement</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A smart , provocative drama that does the near...</td>\n",
       "      <td>[smart, provoc, drama, nearli, imposs, get, sk...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A smart , provocative drama that does the near...</td>\n",
       "      <td>[smart, provoc, drama, nearli, imposs, get, sk...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A smart , provocative drama that does the near...</td>\n",
       "      <td>[smart, provoc, drama, nearli, imposs]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A smart , provocative drama that does the near...</td>\n",
       "      <td>[smart, provoc, drama, nearli, imposs]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>smart , provocative drama\\n</td>\n",
       "      <td>[smart, provoc, drama]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>a particularly good film\\n</td>\n",
       "      <td>[particularli, good, film]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>particularly good film\\n</td>\n",
       "      <td>[particularli, good, film]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>particularly good\\n</td>\n",
       "      <td>[particularli, good]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>surprisingly ` solid ' achievement\\n</td>\n",
       "      <td>[surprisingli, solid, achiev]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>One of recent memory 's most thoughtful films ...</td>\n",
       "      <td>[one, recent, memori, thought, film, art, ethi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Phrase  \\\n",
       "0   A smart , provocative drama that does the near...   \n",
       "1   A smart , provocative drama that does the near...   \n",
       "2   A smart , provocative drama that does the near...   \n",
       "3   A smart , provocative drama that does the near...   \n",
       "4                         smart , provocative drama\\n   \n",
       "..                                                ...   \n",
       "45                         a particularly good film\\n   \n",
       "46                           particularly good film\\n   \n",
       "47                                particularly good\\n   \n",
       "48               surprisingly ` solid ' achievement\\n   \n",
       "49  One of recent memory 's most thoughtful films ...   \n",
       "\n",
       "                              Phrase apres traitement  \n",
       "0   [smart, provoc, drama, nearli, imposs, get, sk...  \n",
       "1   [smart, provoc, drama, nearli, imposs, get, sk...  \n",
       "2              [smart, provoc, drama, nearli, imposs]  \n",
       "3              [smart, provoc, drama, nearli, imposs]  \n",
       "4                              [smart, provoc, drama]  \n",
       "..                                                ...  \n",
       "45                         [particularli, good, film]  \n",
       "46                         [particularli, good, film]  \n",
       "47                               [particularli, good]  \n",
       "48                      [surprisingli, solid, achiev]  \n",
       "49  [one, recent, memori, thought, film, art, ethi...  \n",
       "\n",
       "[50 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "treated_pos_test = [pretraitement(doc) for doc in pos_test]\n",
    "pds = pd.DataFrame({\"Phrase\" : pos_test, \"Phrase apres traitement\" : treated_pos_test})\n",
    "pds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pour le document de test negative : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Phrase apres traitement</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>is trying to dupe the viewer into taking it al...</td>\n",
       "      <td>[tri, dupe, viewer, take, import, simpli, movi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>trying to dupe the viewer into taking it all a...</td>\n",
       "      <td>[tri, dupe, viewer, take, import, simpli, movi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>to dupe the viewer into taking it all as Very ...</td>\n",
       "      <td>[dupe, viewer, take, import, simpli, movi, ugl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dupe the viewer into taking it all as Very Imp...</td>\n",
       "      <td>[dupe, viewer, take, import, simpli, movi, ugl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>simply because the movie is ugly to look at an...</td>\n",
       "      <td>[simpli, movi, ugli, look, hollywood, product]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>an utterly incompetent conclusion\\n</td>\n",
       "      <td>[utterli, incompet, conclus]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>utterly incompetent conclusion\\n</td>\n",
       "      <td>[utterli, incompet, conclus]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>utterly incompetent\\n</td>\n",
       "      <td>[utterli, incompet]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Horrendously amateurish filmmaking that is pla...</td>\n",
       "      <td>[horrend, amateurish, filmmak, plainli, dull, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>filmmaking that is plainly dull and visually u...</td>\n",
       "      <td>[filmmak, plainli, dull, visual, ugli, nt, inc...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Phrase  \\\n",
       "0   is trying to dupe the viewer into taking it al...   \n",
       "1   trying to dupe the viewer into taking it all a...   \n",
       "2   to dupe the viewer into taking it all as Very ...   \n",
       "3   dupe the viewer into taking it all as Very Imp...   \n",
       "4   simply because the movie is ugly to look at an...   \n",
       "..                                                ...   \n",
       "45                an utterly incompetent conclusion\\n   \n",
       "46                   utterly incompetent conclusion\\n   \n",
       "47                              utterly incompetent\\n   \n",
       "48  Horrendously amateurish filmmaking that is pla...   \n",
       "49  filmmaking that is plainly dull and visually u...   \n",
       "\n",
       "                              Phrase apres traitement  \n",
       "0   [tri, dupe, viewer, take, import, simpli, movi...  \n",
       "1   [tri, dupe, viewer, take, import, simpli, movi...  \n",
       "2   [dupe, viewer, take, import, simpli, movi, ugl...  \n",
       "3   [dupe, viewer, take, import, simpli, movi, ugl...  \n",
       "4      [simpli, movi, ugli, look, hollywood, product]  \n",
       "..                                                ...  \n",
       "45                       [utterli, incompet, conclus]  \n",
       "46                       [utterli, incompet, conclus]  \n",
       "47                                [utterli, incompet]  \n",
       "48  [horrend, amateurish, filmmak, plainli, dull, ...  \n",
       "49  [filmmak, plainli, dull, visual, ugli, nt, inc...  \n",
       "\n",
       "[50 rows x 2 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "treated_neg_test = [pretraitement(doc) for doc in neg_test]\n",
    "pds = pd.DataFrame({\"Phrase\" : neg_test, \"Phrase apres traitement\" : treated_neg_test})\n",
    "pds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calcule de TF-IDF des document de test\n",
    "\n",
    "### Pour le document de test positive : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Phrase apres traitement</th>\n",
       "      <th>TF-IDF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A smart , provocative drama that does the near...</td>\n",
       "      <td>[smart, provoc, drama, nearli, imposs, get, sk...</td>\n",
       "      <td>[0.24964435612949923, 0.23445089306333636, 0.2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A smart , provocative drama that does the near...</td>\n",
       "      <td>[smart, provoc, drama, nearli, imposs, get, sk...</td>\n",
       "      <td>[0.24964435612949923, 0.23445089306333636, 0.2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A smart , provocative drama that does the near...</td>\n",
       "      <td>[smart, provoc, drama, nearli, imposs]</td>\n",
       "      <td>[0.5991464547107982, 0.5626821433520073, 0.562...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A smart , provocative drama that does the near...</td>\n",
       "      <td>[smart, provoc, drama, nearli, imposs]</td>\n",
       "      <td>[0.5991464547107982, 0.5626821433520073, 0.562...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>smart , provocative drama\\n</td>\n",
       "      <td>[smart, provoc, drama]</td>\n",
       "      <td>[0.9985774245179969, 0.9378035722533454, 0.937...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>a particularly good film\\n</td>\n",
       "      <td>[particularli, good, film]</td>\n",
       "      <td>[1.168852632439994, 0.9985774245179969, 1.1688...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>particularly good film\\n</td>\n",
       "      <td>[particularli, good, film]</td>\n",
       "      <td>[1.168852632439994, 0.9985774245179969, 1.1688...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>particularly good\\n</td>\n",
       "      <td>[particularli, good]</td>\n",
       "      <td>[1.753278948659991, 1.4978661367769954]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>surprisingly ` solid ' achievement\\n</td>\n",
       "      <td>[surprisingli, solid, achiev]</td>\n",
       "      <td>[1.5350567286626973, 1.5350567286626973, 1.535...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>One of recent memory 's most thoughtful films ...</td>\n",
       "      <td>[one, recent, memori, thought, film, art, ethi...</td>\n",
       "      <td>[0.2995732273553991, 0.4605170185988092, 0.460...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Phrase  \\\n",
       "0   A smart , provocative drama that does the near...   \n",
       "1   A smart , provocative drama that does the near...   \n",
       "2   A smart , provocative drama that does the near...   \n",
       "3   A smart , provocative drama that does the near...   \n",
       "4                         smart , provocative drama\\n   \n",
       "..                                                ...   \n",
       "45                         a particularly good film\\n   \n",
       "46                           particularly good film\\n   \n",
       "47                                particularly good\\n   \n",
       "48               surprisingly ` solid ' achievement\\n   \n",
       "49  One of recent memory 's most thoughtful films ...   \n",
       "\n",
       "                              Phrase apres traitement  \\\n",
       "0   [smart, provoc, drama, nearli, imposs, get, sk...   \n",
       "1   [smart, provoc, drama, nearli, imposs, get, sk...   \n",
       "2              [smart, provoc, drama, nearli, imposs]   \n",
       "3              [smart, provoc, drama, nearli, imposs]   \n",
       "4                              [smart, provoc, drama]   \n",
       "..                                                ...   \n",
       "45                         [particularli, good, film]   \n",
       "46                         [particularli, good, film]   \n",
       "47                               [particularli, good]   \n",
       "48                      [surprisingli, solid, achiev]   \n",
       "49  [one, recent, memori, thought, film, art, ethi...   \n",
       "\n",
       "                                               TF-IDF  \n",
       "0   [0.24964435612949923, 0.23445089306333636, 0.2...  \n",
       "1   [0.24964435612949923, 0.23445089306333636, 0.2...  \n",
       "2   [0.5991464547107982, 0.5626821433520073, 0.562...  \n",
       "3   [0.5991464547107982, 0.5626821433520073, 0.562...  \n",
       "4   [0.9985774245179969, 0.9378035722533454, 0.937...  \n",
       "..                                                ...  \n",
       "45  [1.168852632439994, 0.9985774245179969, 1.1688...  \n",
       "46  [1.168852632439994, 0.9985774245179969, 1.1688...  \n",
       "47            [1.753278948659991, 1.4978661367769954]  \n",
       "48  [1.5350567286626973, 1.5350567286626973, 1.535...  \n",
       "49  [0.2995732273553991, 0.4605170185988092, 0.460...  \n",
       "\n",
       "[50 rows x 3 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TFIDf_test_pos = []\n",
    "corpus = treated_neg_test + treated_pos_test\n",
    "\n",
    "for line in treated_pos_test :\n",
    "  TFIDf_test_pos.append(TFIDF(line, corpus))\n",
    "\n",
    "pds = pd.DataFrame({\"Phrase\" : pos_test, \"Phrase apres traitement\" : treated_pos_test, \"TF-IDF\" : TFIDf_test_pos})\n",
    "pds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pour le document de test negative : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Phrase apres traitement</th>\n",
       "      <th>TF-IDF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A smart , provocative drama that does the near...</td>\n",
       "      <td>[smart, provoc, drama, nearli, imposs, get, sk...</td>\n",
       "      <td>[0.24964435612949923, 0.23445089306333636, 0.2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A smart , provocative drama that does the near...</td>\n",
       "      <td>[smart, provoc, drama, nearli, imposs, get, sk...</td>\n",
       "      <td>[0.24964435612949923, 0.23445089306333636, 0.2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A smart , provocative drama that does the near...</td>\n",
       "      <td>[smart, provoc, drama, nearli, imposs]</td>\n",
       "      <td>[0.5991464547107982, 0.5626821433520073, 0.562...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A smart , provocative drama that does the near...</td>\n",
       "      <td>[smart, provoc, drama, nearli, imposs]</td>\n",
       "      <td>[0.5991464547107982, 0.5626821433520073, 0.562...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>smart , provocative drama\\n</td>\n",
       "      <td>[smart, provoc, drama]</td>\n",
       "      <td>[0.9985774245179969, 0.9378035722533454, 0.937...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>a particularly good film\\n</td>\n",
       "      <td>[particularli, good, film]</td>\n",
       "      <td>[1.168852632439994, 0.9985774245179969, 1.1688...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>particularly good film\\n</td>\n",
       "      <td>[particularli, good, film]</td>\n",
       "      <td>[1.168852632439994, 0.9985774245179969, 1.1688...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>particularly good\\n</td>\n",
       "      <td>[particularli, good]</td>\n",
       "      <td>[1.753278948659991, 1.4978661367769954]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>surprisingly ` solid ' achievement\\n</td>\n",
       "      <td>[surprisingli, solid, achiev]</td>\n",
       "      <td>[1.5350567286626973, 1.5350567286626973, 1.535...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>One of recent memory 's most thoughtful films ...</td>\n",
       "      <td>[one, recent, memori, thought, film, art, ethi...</td>\n",
       "      <td>[0.2995732273553991, 0.4605170185988092, 0.460...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Phrase  \\\n",
       "0   A smart , provocative drama that does the near...   \n",
       "1   A smart , provocative drama that does the near...   \n",
       "2   A smart , provocative drama that does the near...   \n",
       "3   A smart , provocative drama that does the near...   \n",
       "4                         smart , provocative drama\\n   \n",
       "..                                                ...   \n",
       "45                         a particularly good film\\n   \n",
       "46                           particularly good film\\n   \n",
       "47                                particularly good\\n   \n",
       "48               surprisingly ` solid ' achievement\\n   \n",
       "49  One of recent memory 's most thoughtful films ...   \n",
       "\n",
       "                              Phrase apres traitement  \\\n",
       "0   [smart, provoc, drama, nearli, imposs, get, sk...   \n",
       "1   [smart, provoc, drama, nearli, imposs, get, sk...   \n",
       "2              [smart, provoc, drama, nearli, imposs]   \n",
       "3              [smart, provoc, drama, nearli, imposs]   \n",
       "4                              [smart, provoc, drama]   \n",
       "..                                                ...   \n",
       "45                         [particularli, good, film]   \n",
       "46                         [particularli, good, film]   \n",
       "47                               [particularli, good]   \n",
       "48                      [surprisingli, solid, achiev]   \n",
       "49  [one, recent, memori, thought, film, art, ethi...   \n",
       "\n",
       "                                               TF-IDF  \n",
       "0   [0.24964435612949923, 0.23445089306333636, 0.2...  \n",
       "1   [0.24964435612949923, 0.23445089306333636, 0.2...  \n",
       "2   [0.5991464547107982, 0.5626821433520073, 0.562...  \n",
       "3   [0.5991464547107982, 0.5626821433520073, 0.562...  \n",
       "4   [0.9985774245179969, 0.9378035722533454, 0.937...  \n",
       "..                                                ...  \n",
       "45  [1.168852632439994, 0.9985774245179969, 1.1688...  \n",
       "46  [1.168852632439994, 0.9985774245179969, 1.1688...  \n",
       "47            [1.753278948659991, 1.4978661367769954]  \n",
       "48  [1.5350567286626973, 1.5350567286626973, 1.535...  \n",
       "49  [0.2995732273553991, 0.4605170185988092, 0.460...  \n",
       "\n",
       "[50 rows x 3 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TFIDf_test_neg = []\n",
    "for line in treated_neg_test :\n",
    "  TFIDf_test_neg.append(TFIDF(line, corpus))\n",
    "  \n",
    "pds = pd.DataFrame({\"Phrase\" : pos_test, \"Phrase apres traitement\" : treated_pos_test, \"TF-IDF\" : TFIDf_test_pos})\n",
    "pds  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calcule des distances\n",
    "\n",
    "### Par la methode de Cosinus : \n",
    "\n",
    "### Pour le document de test positive : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Phrase traite</th>\n",
       "      <th>Distance de pos</th>\n",
       "      <th>Distance de neg</th>\n",
       "      <th>Décision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A smart , provocative drama that does the near...</td>\n",
       "      <td>[smart, provoc, drama, nearli, imposs, get, sk...</td>\n",
       "      <td>0.999108</td>\n",
       "      <td>0.991990</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A smart , provocative drama that does the near...</td>\n",
       "      <td>[smart, provoc, drama, nearli, imposs, get, sk...</td>\n",
       "      <td>0.999108</td>\n",
       "      <td>0.991990</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A smart , provocative drama that does the near...</td>\n",
       "      <td>[smart, provoc, drama, nearli, imposs]</td>\n",
       "      <td>0.997127</td>\n",
       "      <td>0.999533</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A smart , provocative drama that does the near...</td>\n",
       "      <td>[smart, provoc, drama, nearli, imposs]</td>\n",
       "      <td>0.997127</td>\n",
       "      <td>0.999533</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>smart , provocative drama\\n</td>\n",
       "      <td>[smart, provoc, drama]</td>\n",
       "      <td>0.999553</td>\n",
       "      <td>0.999553</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>a particularly good film\\n</td>\n",
       "      <td>[particularli, good, film]</td>\n",
       "      <td>0.997405</td>\n",
       "      <td>0.999971</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>particularly good film\\n</td>\n",
       "      <td>[particularli, good, film]</td>\n",
       "      <td>0.997405</td>\n",
       "      <td>0.999971</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>particularly good\\n</td>\n",
       "      <td>[particularli, good]</td>\n",
       "      <td>0.999530</td>\n",
       "      <td>0.999717</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>surprisingly ` solid ' achievement\\n</td>\n",
       "      <td>[surprisingli, solid, achiev]</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>One of recent memory 's most thoughtful films ...</td>\n",
       "      <td>[one, recent, memori, thought, film, art, ethi...</td>\n",
       "      <td>0.985267</td>\n",
       "      <td>0.984947</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Phrase  \\\n",
       "0   A smart , provocative drama that does the near...   \n",
       "1   A smart , provocative drama that does the near...   \n",
       "2   A smart , provocative drama that does the near...   \n",
       "3   A smart , provocative drama that does the near...   \n",
       "4                         smart , provocative drama\\n   \n",
       "..                                                ...   \n",
       "45                         a particularly good film\\n   \n",
       "46                           particularly good film\\n   \n",
       "47                                particularly good\\n   \n",
       "48               surprisingly ` solid ' achievement\\n   \n",
       "49  One of recent memory 's most thoughtful films ...   \n",
       "\n",
       "                                        Phrase traite  Distance de pos  \\\n",
       "0   [smart, provoc, drama, nearli, imposs, get, sk...         0.999108   \n",
       "1   [smart, provoc, drama, nearli, imposs, get, sk...         0.999108   \n",
       "2              [smart, provoc, drama, nearli, imposs]         0.997127   \n",
       "3              [smart, provoc, drama, nearli, imposs]         0.997127   \n",
       "4                              [smart, provoc, drama]         0.999553   \n",
       "..                                                ...              ...   \n",
       "45                         [particularli, good, film]         0.997405   \n",
       "46                         [particularli, good, film]         0.997405   \n",
       "47                               [particularli, good]         0.999530   \n",
       "48                      [surprisingli, solid, achiev]         1.000000   \n",
       "49  [one, recent, memori, thought, film, art, ethi...         0.985267   \n",
       "\n",
       "    Distance de neg  Décision  \n",
       "0          0.991990  positive  \n",
       "1          0.991990  positive  \n",
       "2          0.999533  negative  \n",
       "3          0.999533  negative  \n",
       "4          0.999553  positive  \n",
       "..              ...       ...  \n",
       "45         0.999971  negative  \n",
       "46         0.999971  negative  \n",
       "47         0.999717  negative  \n",
       "48         1.000000  positive  \n",
       "49         0.984947  positive  \n",
       "\n",
       "[50 rows x 5 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarite_pos_cos = []  # Liste pour stocker les résultats de classification (positive ou négative)\n",
    "Spp = []  # Liste pour stocker les similarités maximales (cosinus) pour la classe positive\n",
    "Snn = []  # Liste pour stocker les similarités maximales (cosinus) pour la classe négative\n",
    "\n",
    "for doc in TFIDf_test_pos:  # Parcourir les vecteurs TF-IDF des documents de test pour la classe positive\n",
    "    Sp = []  # Liste pour stocker les similarités cosinus pour la classe positive\n",
    "    Sn = []  # Liste pour stocker les similarités cosinus pour la classe négative\n",
    "    for refp in TFIDF_pos:  # Parcourir les vecteurs TF-IDF des documents de référence pour la classe positive\n",
    "        Sp.append(simCosine(doc, refp))  # Calculer la similarité cosinus et l'ajouter à Sp\n",
    "    for refn in TFIDF_neg:  # Parcourir les vecteurs TF-IDF des documents de référence pour la classe négative\n",
    "        Sn.append(simCosine(doc, refn))  # Calculer la similarité cosinus et l'ajouter à Sn\n",
    "    Spp.append(max(Sp))  # Stocker la similarité cosinus maximale pour la classe positive\n",
    "    Snn.append(max(Sn))  # Stocker la similarité cosinus maximale pour la classe négative\n",
    "\n",
    "    # Classer le document comme \"positive\" si la similarité maximale pour la classe positive est supérieure\n",
    "    # ou égale à la similarité maximale pour la classe négative ; sinon, le classer comme \"négative\"\n",
    "    similarite_pos_cos.append(\"positive\" if max(Sp) >= max(Sn) else \"negative\")\n",
    "\n",
    "# Créer un DataFrame pour afficher les résultats, y compris les phrases d'origine, les phrases prétraitées,\n",
    "# les distances maximales pour la classe positive et négative, et la décision finale (positive ou négative)\n",
    "pds = pd.DataFrame({\n",
    "    \"Phrase\": pos_test,\n",
    "    \"Phrase traite\": treated_pos_test,\n",
    "    \"Distance de pos\": Spp,\n",
    "    \"Distance de neg\": Snn,\n",
    "    \"Décision\": similarite_pos_cos\n",
    "})\n",
    "\n",
    "pds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pour le document de test negative :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Phrase traite</th>\n",
       "      <th>Distance de pos</th>\n",
       "      <th>Distance de neg</th>\n",
       "      <th>Decision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>is trying to dupe the viewer into taking it al...</td>\n",
       "      <td>[tri, dupe, viewer, take, import, simpli, movi...</td>\n",
       "      <td>0.993949</td>\n",
       "      <td>0.992385</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>trying to dupe the viewer into taking it all a...</td>\n",
       "      <td>[tri, dupe, viewer, take, import, simpli, movi...</td>\n",
       "      <td>0.993949</td>\n",
       "      <td>0.992385</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>to dupe the viewer into taking it all as Very ...</td>\n",
       "      <td>[dupe, viewer, take, import, simpli, movi, ugl...</td>\n",
       "      <td>0.992903</td>\n",
       "      <td>0.995290</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dupe the viewer into taking it all as Very Imp...</td>\n",
       "      <td>[dupe, viewer, take, import, simpli, movi, ugl...</td>\n",
       "      <td>0.992903</td>\n",
       "      <td>0.995290</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>simply because the movie is ugly to look at an...</td>\n",
       "      <td>[simpli, movi, ugli, look, hollywood, product]</td>\n",
       "      <td>0.993870</td>\n",
       "      <td>0.994482</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>an utterly incompetent conclusion\\n</td>\n",
       "      <td>[utterli, incompet, conclus]</td>\n",
       "      <td>0.999700</td>\n",
       "      <td>0.999700</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>utterly incompetent conclusion\\n</td>\n",
       "      <td>[utterli, incompet, conclus]</td>\n",
       "      <td>0.999700</td>\n",
       "      <td>0.999700</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>utterly incompetent\\n</td>\n",
       "      <td>[utterli, incompet]</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Horrendously amateurish filmmaking that is pla...</td>\n",
       "      <td>[horrend, amateurish, filmmak, plainli, dull, ...</td>\n",
       "      <td>0.939806</td>\n",
       "      <td>0.987022</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>filmmaking that is plainly dull and visually u...</td>\n",
       "      <td>[filmmak, plainli, dull, visual, ugli, nt, inc...</td>\n",
       "      <td>0.995345</td>\n",
       "      <td>0.991152</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Phrase  \\\n",
       "0   is trying to dupe the viewer into taking it al...   \n",
       "1   trying to dupe the viewer into taking it all a...   \n",
       "2   to dupe the viewer into taking it all as Very ...   \n",
       "3   dupe the viewer into taking it all as Very Imp...   \n",
       "4   simply because the movie is ugly to look at an...   \n",
       "..                                                ...   \n",
       "45                an utterly incompetent conclusion\\n   \n",
       "46                   utterly incompetent conclusion\\n   \n",
       "47                              utterly incompetent\\n   \n",
       "48  Horrendously amateurish filmmaking that is pla...   \n",
       "49  filmmaking that is plainly dull and visually u...   \n",
       "\n",
       "                                        Phrase traite  Distance de pos  \\\n",
       "0   [tri, dupe, viewer, take, import, simpli, movi...         0.993949   \n",
       "1   [tri, dupe, viewer, take, import, simpli, movi...         0.993949   \n",
       "2   [dupe, viewer, take, import, simpli, movi, ugl...         0.992903   \n",
       "3   [dupe, viewer, take, import, simpli, movi, ugl...         0.992903   \n",
       "4      [simpli, movi, ugli, look, hollywood, product]         0.993870   \n",
       "..                                                ...              ...   \n",
       "45                       [utterli, incompet, conclus]         0.999700   \n",
       "46                       [utterli, incompet, conclus]         0.999700   \n",
       "47                                [utterli, incompet]         1.000000   \n",
       "48  [horrend, amateurish, filmmak, plainli, dull, ...         0.939806   \n",
       "49  [filmmak, plainli, dull, visual, ugli, nt, inc...         0.995345   \n",
       "\n",
       "    Distance de neg  Decision  \n",
       "0          0.992385  positive  \n",
       "1          0.992385  positive  \n",
       "2          0.995290  negative  \n",
       "3          0.995290  negative  \n",
       "4          0.994482  negative  \n",
       "..              ...       ...  \n",
       "45         0.999700  negative  \n",
       "46         0.999700  negative  \n",
       "47         1.000000  negative  \n",
       "48         0.987022  negative  \n",
       "49         0.991152  positive  \n",
       "\n",
       "[50 rows x 5 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarite_neg_cos = []\n",
    "\n",
    "Spp = []\n",
    "Snn = []\n",
    "\n",
    "for doc in TFIDf_test_neg :\n",
    "  Sp = []\n",
    "  Sn = []\n",
    "  for refp in TFIDF_pos :\n",
    "    Sp.append(simCosine(doc, refp))\n",
    "  for refn in TFIDF_neg :\n",
    "    Sn.append(simCosine(doc, refn))\n",
    "  Spp.append(max(Sp))\n",
    "  Snn.append(max(Sn))  \n",
    "  similarite_neg_cos.append(\"positive\" if max(Sp) > max(Sn)  else \"negative\")  \n",
    "\n",
    "pds = pd.DataFrame({\"Phrase\" : neg_test,\"Phrase traite\" : treated_neg_test, \"Distance de pos\" : Spp, \"Distance de neg\" : Snn  ,\"Decision\" : similarite_neg_cos})\n",
    "\n",
    "pds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Par la methode de Bray-Cortis : \n",
    "\n",
    "### Pour le document de test positive : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Phrase traite</th>\n",
       "      <th>Distance de pos</th>\n",
       "      <th>Distance de neg</th>\n",
       "      <th>Decision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A smart , provocative drama that does the near...</td>\n",
       "      <td>[smart, provoc, drama, nearli, imposs, get, sk...</td>\n",
       "      <td>0.056749</td>\n",
       "      <td>0.056749</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A smart , provocative drama that does the near...</td>\n",
       "      <td>[smart, provoc, drama, nearli, imposs, get, sk...</td>\n",
       "      <td>0.056749</td>\n",
       "      <td>0.056749</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A smart , provocative drama that does the near...</td>\n",
       "      <td>[smart, provoc, drama, nearli, imposs]</td>\n",
       "      <td>0.145758</td>\n",
       "      <td>0.145758</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A smart , provocative drama that does the near...</td>\n",
       "      <td>[smart, provoc, drama, nearli, imposs]</td>\n",
       "      <td>0.145758</td>\n",
       "      <td>0.145758</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>smart , provocative drama\\n</td>\n",
       "      <td>[smart, provoc, drama]</td>\n",
       "      <td>0.244375</td>\n",
       "      <td>0.136868</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>a particularly good film\\n</td>\n",
       "      <td>[particularli, good, film]</td>\n",
       "      <td>0.230043</td>\n",
       "      <td>0.129383</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>particularly good film\\n</td>\n",
       "      <td>[particularli, good, film]</td>\n",
       "      <td>0.230043</td>\n",
       "      <td>0.129383</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>particularly good\\n</td>\n",
       "      <td>[particularli, good]</td>\n",
       "      <td>0.143247</td>\n",
       "      <td>0.082943</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>surprisingly ` solid ' achievement\\n</td>\n",
       "      <td>[surprisingli, solid, achiev]</td>\n",
       "      <td>0.196422</td>\n",
       "      <td>0.112489</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>One of recent memory 's most thoughtful films ...</td>\n",
       "      <td>[one, recent, memori, thought, film, art, ethi...</td>\n",
       "      <td>0.062199</td>\n",
       "      <td>0.062199</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Phrase  \\\n",
       "0   A smart , provocative drama that does the near...   \n",
       "1   A smart , provocative drama that does the near...   \n",
       "2   A smart , provocative drama that does the near...   \n",
       "3   A smart , provocative drama that does the near...   \n",
       "4                         smart , provocative drama\\n   \n",
       "..                                                ...   \n",
       "45                         a particularly good film\\n   \n",
       "46                           particularly good film\\n   \n",
       "47                                particularly good\\n   \n",
       "48               surprisingly ` solid ' achievement\\n   \n",
       "49  One of recent memory 's most thoughtful films ...   \n",
       "\n",
       "                                        Phrase traite  Distance de pos  \\\n",
       "0   [smart, provoc, drama, nearli, imposs, get, sk...         0.056749   \n",
       "1   [smart, provoc, drama, nearli, imposs, get, sk...         0.056749   \n",
       "2              [smart, provoc, drama, nearli, imposs]         0.145758   \n",
       "3              [smart, provoc, drama, nearli, imposs]         0.145758   \n",
       "4                              [smart, provoc, drama]         0.244375   \n",
       "..                                                ...              ...   \n",
       "45                         [particularli, good, film]         0.230043   \n",
       "46                         [particularli, good, film]         0.230043   \n",
       "47                               [particularli, good]         0.143247   \n",
       "48                      [surprisingli, solid, achiev]         0.196422   \n",
       "49  [one, recent, memori, thought, film, art, ethi...         0.062199   \n",
       "\n",
       "    Distance de neg  Decision  \n",
       "0          0.056749  positive  \n",
       "1          0.056749  positive  \n",
       "2          0.145758  positive  \n",
       "3          0.145758  positive  \n",
       "4          0.136868  negative  \n",
       "..              ...       ...  \n",
       "45         0.129383  negative  \n",
       "46         0.129383  negative  \n",
       "47         0.082943  negative  \n",
       "48         0.112489  negative  \n",
       "49         0.062199  positive  \n",
       "\n",
       "[50 rows x 5 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarite_pos_bray = []\n",
    "Spp = []\n",
    "Snn = []\n",
    "\n",
    "for doc in TFIDf_test_pos :\n",
    "  Sp = []\n",
    "  Sn = []\n",
    "  for refp in TFIDF_pos :\n",
    "    Sp.append(simBray(doc, refp))\n",
    "  for refn in TFIDF_neg :\n",
    "    Sn.append(simBray(doc, refn))\n",
    "  Spp.append(min(Sp))\n",
    "  Snn.append(min(Sn))  \n",
    "  similarite_pos_bray.append(\"positive\" if min(Sp) <= min(Sn)  else \"negative\")  \n",
    "\n",
    "pds = pd.DataFrame({\"Phrase\" : pos_test,\"Phrase traite\" : treated_pos_test, \"Distance de pos\" : Spp, \"Distance de neg\" : Snn  ,\"Decision\" : similarite_pos_bray})\n",
    "\n",
    "pds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pour le document de test negative : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Phrase traite</th>\n",
       "      <th>Distance de pos</th>\n",
       "      <th>Distance de neg</th>\n",
       "      <th>Decision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>is trying to dupe the viewer into taking it al...</td>\n",
       "      <td>[tri, dupe, viewer, take, import, simpli, movi...</td>\n",
       "      <td>0.086981</td>\n",
       "      <td>0.086981</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>trying to dupe the viewer into taking it all a...</td>\n",
       "      <td>[tri, dupe, viewer, take, import, simpli, movi...</td>\n",
       "      <td>0.086981</td>\n",
       "      <td>0.086981</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>to dupe the viewer into taking it all as Very ...</td>\n",
       "      <td>[dupe, viewer, take, import, simpli, movi, ugl...</td>\n",
       "      <td>0.079733</td>\n",
       "      <td>0.079733</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dupe the viewer into taking it all as Very Imp...</td>\n",
       "      <td>[dupe, viewer, take, import, simpli, movi, ugl...</td>\n",
       "      <td>0.079733</td>\n",
       "      <td>0.079733</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>simply because the movie is ugly to look at an...</td>\n",
       "      <td>[simpli, movi, ugli, look, hollywood, product]</td>\n",
       "      <td>0.128372</td>\n",
       "      <td>0.128372</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>an utterly incompetent conclusion\\n</td>\n",
       "      <td>[utterli, incompet, conclus]</td>\n",
       "      <td>0.213993</td>\n",
       "      <td>0.142283</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>utterly incompetent conclusion\\n</td>\n",
       "      <td>[utterli, incompet, conclus]</td>\n",
       "      <td>0.213993</td>\n",
       "      <td>0.142283</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>utterly incompetent\\n</td>\n",
       "      <td>[utterli, incompet]</td>\n",
       "      <td>0.160271</td>\n",
       "      <td>0.090820</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Horrendously amateurish filmmaking that is pla...</td>\n",
       "      <td>[horrend, amateurish, filmmak, plainli, dull, ...</td>\n",
       "      <td>0.112370</td>\n",
       "      <td>0.112370</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>filmmaking that is plainly dull and visually u...</td>\n",
       "      <td>[filmmak, plainli, dull, visual, ugli, nt, inc...</td>\n",
       "      <td>0.125875</td>\n",
       "      <td>0.125875</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Phrase  \\\n",
       "0   is trying to dupe the viewer into taking it al...   \n",
       "1   trying to dupe the viewer into taking it all a...   \n",
       "2   to dupe the viewer into taking it all as Very ...   \n",
       "3   dupe the viewer into taking it all as Very Imp...   \n",
       "4   simply because the movie is ugly to look at an...   \n",
       "..                                                ...   \n",
       "45                an utterly incompetent conclusion\\n   \n",
       "46                   utterly incompetent conclusion\\n   \n",
       "47                              utterly incompetent\\n   \n",
       "48  Horrendously amateurish filmmaking that is pla...   \n",
       "49  filmmaking that is plainly dull and visually u...   \n",
       "\n",
       "                                        Phrase traite  Distance de pos  \\\n",
       "0   [tri, dupe, viewer, take, import, simpli, movi...         0.086981   \n",
       "1   [tri, dupe, viewer, take, import, simpli, movi...         0.086981   \n",
       "2   [dupe, viewer, take, import, simpli, movi, ugl...         0.079733   \n",
       "3   [dupe, viewer, take, import, simpli, movi, ugl...         0.079733   \n",
       "4      [simpli, movi, ugli, look, hollywood, product]         0.128372   \n",
       "..                                                ...              ...   \n",
       "45                       [utterli, incompet, conclus]         0.213993   \n",
       "46                       [utterli, incompet, conclus]         0.213993   \n",
       "47                                [utterli, incompet]         0.160271   \n",
       "48  [horrend, amateurish, filmmak, plainli, dull, ...         0.112370   \n",
       "49  [filmmak, plainli, dull, visual, ugli, nt, inc...         0.125875   \n",
       "\n",
       "    Distance de neg  Decision  \n",
       "0          0.086981  negative  \n",
       "1          0.086981  negative  \n",
       "2          0.079733  negative  \n",
       "3          0.079733  negative  \n",
       "4          0.128372  negative  \n",
       "..              ...       ...  \n",
       "45         0.142283  negative  \n",
       "46         0.142283  negative  \n",
       "47         0.090820  negative  \n",
       "48         0.112370  negative  \n",
       "49         0.125875  negative  \n",
       "\n",
       "[50 rows x 5 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarite_neg_bray = []\n",
    "\n",
    "Spp = []\n",
    "Snn = []\n",
    "\n",
    "for doc in TFIDf_test_neg :\n",
    "  Sp = []\n",
    "  Sn = []\n",
    "  for refp in TFIDF_pos :\n",
    "    Sp.append(simBray(doc, refp))\n",
    "  for refn in TFIDF_neg :\n",
    "    Sn.append(simBray(doc, refn))\n",
    "  Spp.append(min(Sp))\n",
    "  Snn.append(min(Sn))  \n",
    "  similarite_neg_bray.append(\"positive\" if min(Sp) < min(Sn)  else \"negative\")  \n",
    "\n",
    "pds = pd.DataFrame({\"Phrase\" : neg_test,\"Phrase traite\" : treated_neg_test, \"Distance de pos\" : Spp, \"Distance de neg\" : Snn  ,\"Decision\" : similarite_neg_bray})\n",
    "\n",
    "pds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation de système\n",
    "\n",
    "Maintenant on va calculer les mesures d'evaluation et comparer les deux methodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F-mesure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Cosinuns</th>\n",
       "      <td>69.0</td>\n",
       "      <td>77.142857</td>\n",
       "      <td>54.0</td>\n",
       "      <td>63.529412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bray-Cortis</th>\n",
       "      <td>73.0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>46.0</td>\n",
       "      <td>63.013699</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Accuracy   Precision  Recall   F-mesure\n",
       "Cosinuns         69.0   77.142857    54.0  63.529412\n",
       "Bray-Cortis      73.0  100.000000    46.0  63.013699"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calcule des mesures pour la methode de Cosinuns\n",
    "\n",
    "TP_cos = similarite_pos_cos.count(\"positive\")\n",
    "FP_cos = similarite_neg_cos.count(\"positive\")\n",
    "TN_cos = similarite_neg_cos.count(\"negative\")\n",
    "FN_cos = similarite_pos_cos.count(\"negative\")\n",
    "\n",
    "\n",
    "\n",
    "ac_cos = (TP_cos + TN_cos ) / (TP_cos + TN_cos + FN_cos + FP_cos)\n",
    "prec_cos = TP_cos / (TP_cos + FP_cos)\n",
    "rec_cos = TP_cos / (TP_cos + FN_cos)\n",
    "fmesure_cos = 2 * (prec_cos * rec_cos) / (prec_cos + rec_cos)\n",
    "\n",
    "# Calcule des mesures pour la methode de Bray-Cortis\n",
    "\n",
    "\n",
    "TP_bray = similarite_pos_bray.count(\"positive\")\n",
    "FP_bray = similarite_neg_bray.count(\"positive\")\n",
    "TN_bray = similarite_neg_bray.count(\"negative\")\n",
    "FN_bray = similarite_pos_bray.count(\"negative\")\n",
    "\n",
    "\n",
    "\n",
    "ac_bray = (TP_bray + TN_bray ) / (TP_bray + TN_bray + FN_bray + FP_bray)\n",
    "prec_bray = TP_bray / (TP_bray + FP_bray)\n",
    "rec_bray = TP_bray / (TP_bray + FN_bray)\n",
    "fmesure_bray = 2 * (prec_bray * rec_bray) / (prec_bray + rec_bray)\n",
    "\n",
    "data = {\n",
    "    \"Accuracy\": [ac_cos * 100, ac_bray * 100 ],\n",
    "    \"Precision\": [prec_cos * 100, prec_bray * 100],\n",
    "    \"Recall\": [rec_cos * 100, rec_bray * 100],\n",
    "    \"F-mesure\": [fmesure_cos * 100, fmesure_bray * 100],\n",
    "}\n",
    "\n",
    "# Create the DataFrame\n",
    "pds = pd.DataFrame(data, index=[\"Cosinuns\", \"Bray-Cortis\"])\n",
    "\n",
    "pds\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
